{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5bb632-b6b6-462e-ab31-5e149fd421e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a803cf-8e2a-469a-b03a-77951b1caa5f",
   "metadata": {},
   "source": [
    "## Meta Llama3 Base and Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b41b66-9d34-48de-aa32-7350d21f1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8157047b41644bcdbc1853e9c1fe6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type='nf4',\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "device_map = 'auto'\n",
    "device = 'cuda'\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=nf4_config,device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9330e07-245c-4bc3-aefb-c804cf1610f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'kwsp itu apa?',\n",
    "    \"Apakah maksud perkataan 'integriti'?\",\n",
    "    \"Terangkan perbezaan antara 'hormat' dan 'takut.'\",\n",
    "    \"Translate the following English sentence to Malay: 'The cat is sitting on the table.'\",\n",
    "    \"Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.'\",\n",
    "    \"Correct the following sentence: Me wants to go store.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef00c9b-019f-461f-b5f1-1d7928528bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sani/miniconda3/envs/mergekit/lib/python3.10/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2024-04-20 10:00:37.566776: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-20 10:00:38.277483: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 10:00:39.651643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: kwsp itu apa?\n",
      "kwsp itu apa? (What is the name of the place?) (2) Apa nama kota itu? (What is the name of the city?) (3) Apa nama negara itu? (What is the name of the country?) (4) Apa nama pulau itu? (What is the name of the\n",
      "************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sani/miniconda3/envs/mergekit/lib/python3.10/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Apakah maksud perkataan 'integriti'?\n",
      "Apakah maksud perkataan 'integriti'? (1 markah)\n",
      "2. Apakah maksud perkataan 'kejujuran'? (1 markah)\n",
      "3. Apakah maksud perkataan 'kebenaran'? (1 markah)\n",
      "4. Apakah maksud perkataan 'keadilan'? (1 markah)\n",
      "5\n",
      "************************************************************************************************************************\n",
      "input: Terangkan perbezaan antara 'hormat' dan 'takut.'\n",
      "Terangkan perbezaan antara 'hormat' dan 'takut.'\"\n",
      "    \"Explain the difference between 'hormat' and 'takut.'\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghorm\n",
      "************************************************************************************************************************\n",
      "input: Translate the following English sentence to Malay: 'The cat is sitting on the table.'\n",
      "Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "* [2] Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "* [3] Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "*\n",
      "************************************************************************************************************************\n",
      "input: Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.'\n",
      "Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.' (I like eating nasi lemak.)\"\n",
      "    \"\"\"\n",
      "    # Your code here\n",
      "    return \"I like eating nasi lemak.\"\n",
      "<|end_of_text|>\n",
      "************************************************************************************************************************\n",
      "input: Correct the following sentence: Me wants to go store.\n",
      "Correct the following sentence: Me wants to go store. The sentence is incorrect because the subject and verb do not agree. The subject is Me, which is singular. The verb is wants, which is plural. The sentence should be corrected to read: I want to go to the store. The subject and verb agree. The sentence is correct. The subject is I, which\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, pad_token_id=tokenizer.eos_token_id,do_sample=False)\n",
    "    decoded = tokenizer.batch_decode(outputs)\n",
    "    print('input:',text)\n",
    "    print(decoded[0])\n",
    "    print('***'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46871d17-d6a8-482a-937b-1e3c6d48ced3",
   "metadata": {},
   "source": [
    "## Basically Base ni bagus untuk generate next sentence bukan untuk menjawab soalan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86f9fc6-ce95-43d5-bdd0-31fd4cec2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da21cbb5eff94a869ca1f68dbf85ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type='nf4',\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "device_map = 'auto'\n",
    "device = 'cuda'\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=nf4_config,device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e76ea4f-6474-47bc-8b5f-b1de795335ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: kwsp itu apa?\n",
      "\n",
      "\n",
      "Kwsp is an abbreviation for \"Kumpulan Wang Simpanan Pekerja\" which is a Malay phrase that translates to \"Employee Provident Fund\" in English.\n",
      "\n",
      "Kwsp is a mandatory savings plan in Malaysia that requires employers to contribute a certain percentage of their employees' salaries to\n",
      "************************************************************************************************************************\n",
      "input: Apakah maksud perkataan 'integriti'?\n",
      "\n",
      "\n",
      "Perkataan \"integriti\" dalam bahasa Melayu bererti \"kesucian\" atau \"kesederhanaan\". Ia merujuk kepada sifat seseorang yang memiliki moral yang tinggi, jujur, dan tidak mudah terpengar\n",
      "************************************************************************************************************************\n",
      "input: Terangkan perbezaan antara 'hormat' dan 'takut.'\n",
      "\n",
      "\n",
      "A great question!\n",
      "\n",
      "In Malay, \"hormat\" and \"takut\" are two words that are often confused with each other, but they have distinct meanings.\n",
      "\n",
      "**Hormat** (respect) refers to a feeling of admiration, esteem, or reverence for someone or something. It is\n",
      "************************************************************************************************************************\n",
      "input: Translate the following English sentence to Malay: 'The cat is sitting on the table.'\n",
      "\n",
      "\n",
      "The translation of the sentence \"The cat is sitting on the table\" in Malay is:\n",
      "\n",
      "\"Kucing itu duduk di atas meja.\"\n",
      "\n",
      "Here's a breakdown of the translation:\n",
      "\n",
      "* \"The cat\" is translated to \"Kucing itu\", where \"itu\" is a pronoun meaning\n",
      "************************************************************************************************************************\n",
      "input: Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.'\n",
      "\n",
      "\n",
      "The translation of the Malay sentence \"Saya suka makan nasi lemak\" to English is:\n",
      "\n",
      "\"I like eating nasi lemak.\"\n",
      "\n",
      "(Note: \"Nasi lemak\" is a popular Malaysian dish made with fragrant rice cooked in coconut milk, pandan leaves, and sometimes served\n",
      "************************************************************************************************************************\n",
      "input: Correct the following sentence: Me wants to go store.\n",
      "\n",
      "\n",
      "A classic example of a sentence that needs some correction!\n",
      "\n",
      "The corrected sentence would be:\n",
      "\n",
      "\"I want to go to the store.\"\n",
      "\n",
      "Here's what changed:\n",
      "\n",
      "* \"Me\" is a subject pronoun (e.g., \"Me is going to the store\"), but in this sentence, we need a first\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    msg = [\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=encodeds.to(\"cuda\"), max_new_tokens=64, pad_token_id=tokenizer.eos_token_id,do_sample=False)\n",
    "    decoded = tokenizer.batch_decode(outputs)\n",
    "    print('input:',text)\n",
    "    print(decoded[0].split(\"<|end_header_id|>\")[2].split(\"<|eot_id|>\")[0])\n",
    "    print('***'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca51887-4632-4093-8b0a-81b6226845b1",
   "metadata": {},
   "source": [
    "## Kadang2 Instruct akan reply dalam bahasa melayu sebab dia memang dah tau conteks cuma dia diajar hanya untuk reply dalam English. Basically Base model dah tau tentang Malaysia(nasi lemak, kucing, etc) tapi time Instruct dia dah diajar untuk reply dalam English je."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e2b78-c13a-4514-af79-8d9364554834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5cb08-3b15-438f-965e-0deb2c695f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b93ed2-dd26-4dc3-afbe-646f919dea84",
   "metadata": {},
   "source": [
    "## Masa untuk tunjuk beza finetune base dengan transformed instruct dari base untuk bahasa melayu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b0f752-4777-4cd7-9872-cea081b12842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf5b82d-b1fa-4e1b-8414-0fd1741cd819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809de4c7d4c74e838f5fc46521005450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"../llm/model/\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type='nf4',\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "device_map = 'auto'\n",
    "device = 'cuda'\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=nf4_config,device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4777b920-1396-468c-bd21-14dc8319961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: kwsp itu apa?\n",
      "kwsp itu apa? (What is the name of the place?) (2) Apa nama kota itu? (What is the name of the city?) (3) Apa nama negara itu? (What is the name of the country?) (4) Apa nama pulau itu? (What is the name of the\n",
      "************************************************************************************************************************\n",
      "input: Apakah maksud perkataan 'integriti'?\n",
      "Apakah maksud perkataan 'integriti'? (1 markah)\n",
      "2. Apakah maksud perkataan 'kejujuran'? (1 markah)\n",
      "3. Apakah maksud perkataan 'kebenaran'? (1 markah)\n",
      "4. Apakah maksud perkataan 'keadilan'? (1 markah)\n",
      "5\n",
      "************************************************************************************************************************\n",
      "input: Terangkan perbezaan antara 'hormat' dan 'takut.'\n",
      "Terangkan perbezaan antara 'hormat' dan 'takut.'\"\n",
      "    \"Explain the difference between 'hormat' and 'takut.'\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghormati\" = \"to respect\"\n",
      "    \"Menghorm\n",
      "************************************************************************************************************************\n",
      "input: Translate the following English sentence to Malay: 'The cat is sitting on the table.'\n",
      "Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "* [2] Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "* [3] Translate the following English sentence to Malay: 'The cat is sitting on the table.' (Use the appropriate pronoun.)\n",
      "*\n",
      "************************************************************************************************************************\n",
      "input: Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.'\n",
      "Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.' (I like eating nasi lemak.)\"\n",
      "    \"\"\"\n",
      "    # Your code here\n",
      "    return \"I like eating nasi lemak.\"\n",
      "<|end_of_text|>\n",
      "************************************************************************************************************************\n",
      "input: Correct the following sentence: Me wants to go store.\n",
      "Correct the following sentence: Me wants to go store. The sentence is incorrect because the subject and verb do not agree. The subject is Me, which is singular. The verb is wants, which is plural. The correct sentence is: I want to go to the store. The subject is I, which is singular. The verb is want, which is singular. The subject\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, pad_token_id=tokenizer.eos_token_id,do_sample=False)\n",
    "    decoded = tokenizer.batch_decode(outputs)\n",
    "    print('input:',text)\n",
    "    print(decoded[0])\n",
    "    print('***'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a20e93-8843-4340-8063-5d15a92772ce",
   "metadata": {},
   "source": [
    "## Model dekat atas ni dah finetune llama3 base dengan bahasa melayu, tak ada banyak perbezaan dari segi output, tapi kalau inspect probability untuk next token akan bnyk berbeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964af8bf-2438-4c95-a44f-ba93e99203b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, \"instruct_vector\",device_map=device_map,quantization_config=nf4_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a686c06e-e3b9-433d-8cb1-fa543c09dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: kwsp itu apa?\n",
      "\n",
      "\n",
      "KWSP adalah singkatan dari \"Kumpulan Wang Simpanan Pekerja\" atau \"Employee Provident Fund\" dalam bahasa Inggris. KWSP adalah sebuah institusi yang bertugas mengumpulkan dan menyimpan dana pensiun untuk pekerja Malaysia. Dana tersebut akan digunakan untuk\n",
      "************************************************************************************************************************\n",
      "input: Apakah maksud perkataan 'integriti'?\n",
      "\n",
      "\n",
      "Perkataan 'integriti' dalam bahasa Melayu bermaksud 'kesucian' atau 'kesahihan'. Ia juga dapat dikaitkan dengan 'kesetiaan' atau 'kesetiaan kepada nilai atau prinsip tertentu'.\n",
      "\n",
      "Dalam kont\n",
      "************************************************************************************************************************\n",
      "input: Terangkan perbezaan antara 'hormat' dan 'takut.'\n",
      "\n",
      "\n",
      "\"Hormat\" dan \"takut\" adalah dua kata yang memiliki makna yang berbeza, walaupun mereka memiliki beberapa kesamaan.\n",
      "\n",
      "\"Hormat\" adalah kata yang bermakna \"penghormatan\", \"penghargaan\", atau \"penghormatan yang layak\".\n",
      "************************************************************************************************************************\n",
      "input: Translate the following English sentence to Malay: 'The cat is sitting on the table.'\n",
      "\n",
      "\n",
      "Here's the translation:\n",
      "\n",
      "\"Kucing itu duduk di atas meja.\"\n",
      "\n",
      "Note: I've used the word \"itu\" to indicate the cat, since it's a specific cat being referred to. If you want to use a generic word for cat, you can use \"kucing\" alone.\n",
      "************************************************************************************************************************\n",
      "input: Translate the following Malay sentence to English: 'Saya suka makan nasi lemak.'\n",
      "\n",
      "\n",
      "The Malay sentence \"Saya suka makan nasi lemak\" translates to \"I like to eat nasi lemak.\" Nasi lemak is a popular dish in Malaysia and Singapore, consisting of rice cooked in coconut milk and served with a variety of accompaniments.\n",
      "************************************************************************************************************************\n",
      "input: Correct the following sentence: Me wants to go store.\n",
      "\n",
      "\n",
      "The corrected sentence would be: I want to go to the store.\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    msg = [\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=encodeds.to(\"cuda\"), max_new_tokens=64, pad_token_id=tokenizer.eos_token_id,do_sample=False)\n",
    "    decoded = tokenizer.batch_decode(outputs)\n",
    "    print('input:',text)\n",
    "    print(decoded[0].split(\"<|end_header_id|>\")[2].split(\"<|eot_id|>\")[0])\n",
    "    print('***'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91beac72-c11d-47e4-9359-5a1231680e96",
   "metadata": {},
   "source": [
    "## Tadaaa, Transformed llama3 Instruct dari base tadi dah bole jawab dalam Bahasa Melayu kalau tanya dalam BM. So far aku pakai model ni untuk experiment je, kalau ada berminat baru push ke huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8d2d3-81c4-4cfb-9652-007acff05ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
